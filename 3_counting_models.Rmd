---
title: "NYC Shootings incidents and Criminality <br> Counting models"
author: "Sebastiano Quintavale - 878500"
output:
    html_document:
        toc: true
        toc_float: true
        theme: cerulean
        highlight: tango
---

## 1. Introduction 

The purpose of this notebook is to expand on the analyses conducted in the previous notebook [`2_linear_models.Rmd`](2_linear_models.Rmd), which employed linear regression models to predict the number of shootings in New York City.

This notebook extends the analysis by using count models to predict the number of shootings in New York City. The main goal is to investigate whether this second type of modeling, which adopts a family of models more appropriate for the data in question, can lead to better results in terms of both predictions and interpretation.

The study will begin with an extensive use of Poisson models, which will later be compared with other count models such as Quasi-Poisson, Negative Binomial, and Generalized Additive Models.


```{r echo=FALSE, include=FALSE}

# 1. RMardown styling
knitr::opts_chunk$set(echo=FALSE)
knitr::opts_chunk$set(fig.width=8, fig.height=6, fig.align='center')
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
# 2. Project environment setup
source("src/init.R")

```

```{r}

# Load data
crimes <- read.csv(PATHS$NycMonthCrimes)

# Add discrete version for Month and Year
prepare_out <- prepare_crimes(crimes_df=crimes)

crimes      <- prepare_out$df
CRIME_NAMES <- prepare_out$crime_names

rm(prepare_out)

# Split Train and Test
split <- train_test_split_by_year(df_ = crimes, year_test = YEAR_TEST)
crimes <- split$train
crimes_test <- split$test
rm(split)

split_out <- split_statenisland(crimes=crimes, crimes_test=crimes_test)

crimes         <- split_out$crimes
crimes_test    <- split_out$crimes_test
si_crimes      <- split_out$si_crimes
si_crimes_test <- split_out$si_crimes_test

rm(split_out)



crimes <- prepare_outliers(crimes)

```

---

## 2. Poisson Regression

Let's start by using a Poisson model to predict the number of shootings in New York City.


### 2.1. Model assumptions

First, it is important to verify that our data are consistent with the assumptions required by this type of model. Specifically, the model assumes that the response variable is a random variable that follows a Poisson distribution. A natural consequence of this is the strong assumption that the mean and variance of the count are equal.

Let's try to verify if this assumption is generally met, or if it holds at the Borough level.


```{r}
mean_var <- data.frame(
    Mean = c(tapply(crimes$Shootings, crimes$Borough, mean), mean(crimes$Shootings)), 
    Var  = c(tapply(crimes$Shootings, crimes$Borough, var ), var (crimes$Shootings))
)
rownames(mean_var)[5] <- "NewYorkCity"

mean_var

```

Clearly, the variance is greater than the mean, indicating that overdispersion has occurred. In light of this, it would be more appropriate to transition to a Quasi-Poisson model, which relaxes this assumption by assuming a certain overdispersion parameter. However, it is worth noting that the difference between the two is not in the prediction, but in the estimation of confidence intervals and thus in the uncertainty of the model.

Using a Quasi-Poisson model also makes it impossible to use metrics such as $AIC$ and $BIC$. Therefore, Poisson models will still be employed for model selection to leverage on the comprison of these metrics, but knowing the final model will be a Quasi-Poisson.


### 2.2. Poisson models

Let's begin constructing multiple generalized linear Poisson regression models to predict the number of shootings in New York City. As done previously, Manhattan serves as the reference level for the Boroughs, while for monthly predictors, we use a contrast that references the predictors to the mean of the observations.

```{r}

# Add constrast
contrasts(crimes     $MonthName) <- contr.sum(12)
contrasts(crimes_test$MonthName) <- contr.sum(12)

pois_models <- list()


```

```{r}
plot_prediction <- function(model, name, test=FALSE) {

    if(!test) {
        df_ <- crimes
    } else {
        df_ <- crimes_test
    }

    invisible(
    plot_model_predictions_per_level_over_time(
        model = model,
        df_ =df_,
        y = "Shootings",
        levels = "Borough",
        title = paste("Shootings per Borough Prediction -", name, "-", ifelse(!test, "Training", "Test"), "set"),
        ylab = "Shootings incidents",
        level = LEVEL,
        ticks = ifelse(!test, 12, 5),
        lwd = 0.35,
        lwd_observations = 0.35,
        colors = unlist(PALETTE$boroughs),
        grid_rows = 2,
        glmnet_predictors = SHRINKAGE_PREDICTORS
    )
    )

}
```

#### 2.2.1. Baselines

Let's use two baseline models to compare with the more complex models that will be built later. Specifically, we will use two models that predict the overall average of shootings, and the average shootings per Borough.


The mean baseline.

```{r}

pois_models$baseline <- glm(
    Shootings ~ 1.,
    data = crimes,
    family = "poisson"
)

glm_diagnostic(pois_models$baseline, name = "Baseline")
```

The borough mean baseline.

```{r}
pois_models$baseline_borough <- glm(
    Shootings ~ Borough,
    data = crimes,
    family = "poisson"
)

glm_diagnostic(pois_models$baseline_borough, name = "Baseline Borough")


```

#### 2.2.2. Seasonal model

From previous analyses, it emerged that a fundamental component for predicting the number of shootings is the seasonal component. Let's therefore try to model this component using a Poisson model in two versions: one that uses the monthly average and another that uses a periodic modeling approach.

By using month discrete levels.

```{r}

pois_models$seasonal <- glm(
    Shootings ~ Borough + MonthName,
    data = crimes,
    family = "poisson"
)

glm_diagnostic(
    model=pois_models$seasonal,  df_=crimes,
    residuals = TRUE, name = "Seasonal model"
)

```

By using periodic time component.

```{r}

pois_models$seasonal_periodic <- glm(
    Shootings ~ Borough + SinT + CosT,
    data = crimes,
    family = "poisson"
)

glm_diagnostic(
    model=pois_models$seasonal_periodic,  df_=crimes,
    residuals = TRUE, name = "Seasonal Periodic model"
)

```

It is now interesting to compare these models with their linear counterpart in terms of the $AIC$ and $BIC$ metrics, as well as their predictions on the test set, particularly focusing on their uncertainty.


```{r}

knit_table(stats_to_table(get_models_prediction_stats(
    models = list(
        Seasonal     = lm(Shootings ~ Borough + MonthName,   data=crimes),
        Periodic     = lm(Shootings ~ Borough + SinT + CosT, data=crimes),
        SeasonalPois = pois_models$seasonal,
        PeriodicPois = pois_models$seasonal_periodic
    ),
    df_ = crimes_test,
    y = "Shootings"
))[, -c(1, 2)])

```

If Poisson models tend to perform worse in terms of $AIC$ and $BIC$, their clear advantage lies in reducing prediction variance, achieved through stronger assumptions about the observed data.

Comparing MSE between the two models using monthly averages isn't particularly insightful as it only employs discrete levels. However, there is an improvement for the periodic model both in terms of MSE and, importantly, uncertainty.


#### 2.2.3. Predicting the trend

An important aspect that linear models have failed to capture is the long-term trend component such as shooting trends. Let's see if a Poisson model can capture this trend.

Firstly, we'll use a model that includes only time as a predictor, along with its sine and cosine with a period of 12 to model monthly seasonality.

```{r}

pois_models$trended <- glm(
    Shootings ~ Borough + SinT + CosT + T,
    data = crimes,
    family = poisson
)

glm_diagnostic(
    model=pois_models$trended, 
    df_=crimes,
    residuals = TRUE,
    name = "Trended model"
)

pois_models$trended <- NULL
```

From the `T` residuals we can see that including time linearly is not sufficient to capture the trend. Let's try including a third-degree polynomial to better capture the trend, as done previously with linear models.

```{r}

pois_models$trended2 <- glm(
    Shootings ~ Borough + SinT + CosT + poly(T, 3),
    data = crimes,
    family = poisson
)

glm_diagnostic(
    model=pois_models$trended2, 
    df_=crimes,
    residuals = TRUE,
    name = "Trended model V2"
)
```

The model assumptions are now better respected. Let's see how the model performs in predicting on the training set.

```{r}
plot_prediction(pois_models$trended2, "Trended")
```

As with the linear model, the model is very accurate, to the point of anticipating possible overfitting issues. Despite this, we can already appreciate a significant reduction in the uncertainty of the predictions compared to the previous scenario.

Let's now see the model's performance on the test set.

```{r}
plot_prediction(pois_models$trended2, "Trended", test=TRUE)
```

As expected, the model poorly generalizes on long-term predictions, where the fitted trend information no longer appears valid and progressvely become more incertain with the time.

However, compared to the linear counterpart, the model seems to perform significantly better in terms of short-term prediction. Let's compare the models in the first 3 months of the test set.

```{r}
# Good for short-term prediction. Compare with others

linear_trended <- lm(
    Shootings ~ T + I(T^2) + I(T^3) + SinT + CosT + Borough,
    data = crimes
)

# First term test

stats_out <- data.frame(
    "tmp"  = c(1, 2)
)
first_test_epoch <- crimes_test$T[1]

for(MONTHS in 1:3) {

    short_term_test <- crimes_test[
        crimes_test$T >= first_test_epoch &
        crimes_test$T <= first_test_epoch + MONTHS,
    ]

    s_out <- stats_to_table(
        stats = get_models_prediction_stats(
            models = list(
                Linear  = linear_trended,
                Poisson = pois_models$trended2
            ),
            df_ = short_term_test,
            y = "Shootings"
    ))[, -c(1:4)]

    colnames(s_out) <- c(paste0("MSE(", MONTHS, ")"), paste0("AvgSE(", MONTHS, ")"))

    stats_out <- cbind(stats_out, s_out)

}

stats_out$tmp <- NULL

knit_table(stats_out)


rm(list = c(
    "linear_trended", "stats_out", "first_test_epoch", "s_out", "MONTHS"
))

```

As evident from the table, the Poisson model is indeed better at capturing short-term information compared to the linear model, with also less uncertainty.

#### 2.2.4. Total Arrests model

Let's now introduce the total number of arrests in the previous month as a predictor for the number of shootings that occurred. The term is used quadratically to better capture the interaction between the two variables.

```{r}
pois_models$totarrests <- glm(
    Shootings ~ Borough + CosT + SinT + TotArrests + I(TotArrests^2),
    data = crimes, family = "poisson"
)

glm_diagnostic(
    pois_models$totarrests, df_=crimes,
    residuals = TRUE,
    name = "Total Arrests model"
)

```

All introduced predictors appear to be significant, and even the residual plot looks satisfactory. Let's visualize the model's prediction on the training set.

```{r}
plot_prediction(pois_models$totarrests, "Total Arrests")
```

seasonal_periodic
```{r}
plot_prediction(pois_models$totarrests, "Total Arrests", test=TRUE)

```

The model appears to capture a certain trend compared to the observations but is still dominated by a seasonal component. It especially has a very narrow confidence interval, particularly in the two boroughs of Manhattan and Queens, which record fewer shooting incidents.

The model improves the model quality compared to using seasonality alone.

```{r}
knit_table(stats_to_table(get_models_prediction_stats(
    models = list(
        Seasonal = pois_models$seasonal_periodic,
        Arrests  = pois_models$totarrests
    ),
    df_ = crimes_test,
    y = "Shootings"
))[, -c(1, 2, 5, 6)])
```


#### 2.2.5. Shirnkage method

Once established how the number of arrests is a significant predictor to enhance seasonal information, it is important to consider whether specific types of crimes can be significant predictors for the number of shootings that occur.

Firstly, we will use a shrinkage method to select the most significant predictors.

We will use three different values of alpha for elastic-net regularization:

- $\alpha = `r ALPHA_GLMNET[1]`$: Ridge regularization.
- $\alpha = `r ALPHA_GLMNET[3]`$: Lasso regularization.
- $\alpha = `r ALPHA_GLMNET[2]`$: A combination close to pure Lasso.

We will also use two selection metrics: `1se` and `min`, indicating whether to select the minimum lambda selected by cross-validation or the lambda that gives a more regularized model within one standard error of the minimum lambda.

```{r}

SHRINKAGE_PREDICTORS <- c("T", "CosT", "SinT", "Borough", CRIME_NAMES)

gs <- shrinkage_grid_search(
    df_ = crimes[, c(SHRINKAGE_PREDICTORS, "Shootings")], 
    y="Shootings", 
    alphas=ALPHA_GLMNET,
    family="poisson"
)

knit_table(zero_to_point(gs))

```

Looking at the most parsimonious model, the only crime that survives regularization and appears to be a significant predictor for the number of shootings is `Murder`. It's also interesting to note how the model fits a slight decreasing effect for `T` over time. The selection process seems to favor the temporal and spatial components over those related to crime.

Let's visualize the cross-validation for the LASSO model.

```{r}
pois_models$lasso <- shrinkage_selection(
    df_ = crimes[, c(SHRINKAGE_PREDICTORS, "Shootings")],
    y = "Shootings",
    type = "1se",
    alpha = 1,
    title = paste("Lasso selection for NYC"),
    family="poisson"
)

```

Let's now see how the LASSO model performs on the training set.

```{r}

plot_prediction(pois_models$lasso, "Lasso Shrinkage")

```

Let's also visualize prediction on the Test Set.

```{r}
plot_prediction(pois_models$lasso, "Lasso Shrinkage", test=TRUE)

```

Interestingly, the model appears less smooth and seems to adjust to slight dips and peaks, likely due to murder arrests. It's important to note the challenge of calculating confidence intervals for a LASSO model, whose primary goal is predictor selection.

#### 2.2.6. Stepwise model

Lastly, let's try automatically selecting predictors using a stepwise method with a $BIC$ criterion.

```{r}

pois_models$stepwise <- step(
    glm(Shootings ~ 1, data=crimes[, c("Shootings", SHRINKAGE_PREDICTORS)], family="poisson"),
    scope = list(
        lower = glm(Shootings ~ 1, data=crimes[, c("Shootings", SHRINKAGE_PREDICTORS)], family="poisson"), 
        upper = glm(Shootings ~ ., data=crimes[, c("Shootings", SHRINKAGE_PREDICTORS)], family="poisson")
    ),
    direction = "both",
    k = log(nrow(crimes))
)

```

The final model selects, along with the temporal variables, four different crimes: `DrugRelated`, `Burglary`, `Murder`, and `ViolenceAndDisruption`.

Let's visualize its summary.

```{r}
summary(pois_models$stepwise)
```

All selected predictors are significant; however, we need to be cautious as some are known to be potentially collinear. Let's verify this by analyzing their generalized Variance Inflation Factor (gVIF).


```{r}
gvif_diagnostic(pois_models$stepwise)
```

The model is indeed somewhat collinear due to `DrugRelated` and `ViolenceAndDisruption`, as well as an interaction among the crimes. Additionally, the time predictor `T` also shows a high level of collinearity, which can be explained by its modeling of a temporal trend likely influenced by some form of arrest increasing or decreasing over time, like drug-related crimes.


#### 2.2.7 Crimes specific arrests

In light of the previous collinearity issues, we will fit a second model where we remove collinear predictors. We will then select, along with the temporal modeling and boroughs, only specific types of crimes `Theft`, `DrugRelated`, and `Burglary`.

```{r}
pois_models$crimes <- glm(
    Shootings ~ Borough + DrugRelated + Theft +  Burglary +
        SinT + CosT,
    data = crimes, family = "poisson"
)

glm_diagnostic(
    pois_models$crimes, df_=crimes,
    residuals = TRUE,
    name = "Crime specific model"
)
``` 

Let's examine the predictions of this final model on the training and test sets.

```{r}
plot_prediction(pois_models$crimes, "Crimes")
plot_prediction(pois_models$crimes, "Crimes", test = TRUE)
```

### 2.3. Model comparison

Let's compare the fitted models in terms of $AIC$ and $BIC$, and analyze their predictive power in terms of MSE and average prediction SE (Standard Error).

```{r}
pois_models <- list(
    "Baseline"          = pois_models$baseline,
    "Baseline Borough"  = pois_models$baseline_borough,
    "Month Seasonality" = pois_models$seasonal,
    "Time Periodic"     = pois_models$seasonal_periodic,
    "Season and Trend"  = pois_models$trended2,
    "Total Arrests"     = pois_models$totarrests,
    "Shrinkage - LASSO" = pois_models$lasso,
    "Stepwise - BIC"    = pois_models$stepwise,
    "Crime specific"    = pois_models$crimes
)


```

```{r}

models_stats <- get_models_prediction_stats(
    models = pois_models,
    df_ = crimes_test,
    y = "Shootings",
    glmnet_predictors = SHRINKAGE_PREDICTORS
)

out_table <- stats_to_table(models_stats)[, -c(1, 2)]
out_table <- out_table[order(out_table$MSE), ]

knit_table(out_table)

```

All fitted models perform significantly better than the baselines.

The best model incorporates quadratic information about the total number of arrests in the previous month in addition to the seasonal effect, capturing the nature of shootings increasing when there are few or many arrests. This model is also notable for its low uncertainty, remaining well below unity.

In general, other models that add information about specific crimes, albeit in a linear manner, show similar performance but with increased uncertainty (except for the LASSO model).

Therefore, we can conclude that there is statistical significance in how the number of arrests reflects a crime condition in the city that subsequently impacts the number of shootings occurring in the near future.

---

## 3. Counting Models Comparison

Considering the factors that best help model the number of shootings using Poisson models, let's now compare them with other count models such as Quasi-Poisson, Negative Binomial, and Generalized Additive Models (GAM).

To do this, we will use a model that includes three different types of crimes as predictors: `DrugRelated`, `Theft`, and `Burglary`. While this model may not be the best among those analyzed, it still shows a very good MSE and importantly allows for a better comparison between counting models, especially when we intervene with GAMs to model potential non-linearity in crimes.


```{r}
model.pois <- glm(
    Shootings ~ Borough + SinT + CosT +
        DrugRelated + Murder + Burglary,
    data = crimes, family = "poisson"
)

```

### 3.1. Quasi-poisson

As anticipated, our response variable, namely the number of shootings, does not strictly meet the assumptions that the Poisson model requires, which are equal mean and variance.

Therefore, let's proceed to relax this assumption by using a Quasi-Poisson model, which assumes some dispersion, typically overdispersion, in the data.


```{r}
model.quasipois <- glm(
    Shootings ~ Borough + SinT + CosT +
        DrugRelated + Murder + Burglary,
    data = crimes, family = "quasipoisson"
)
```

Let's first review the summary of the Poisson model.

```{r}
summary(model.pois)
```

It showed all predictors involved as highly significant. Let's see if the same holds true for the Quasi-Poisson model.

```{r}

summary(model.quasipois)
```

Compared to before, the models remain significant, but with slightly less significance for `Burglary`.

More importantly, the model estimates a dispersion parameter equal to $`r (summary(model.quasipois))$dispersion`$.

The coefficients of the two models are the same, and so will be the predictions, but with a wider confidence interval for the Quasi-Poisson model. Let's examine the behavior in an example dataset where we vary only the number of arrests related to drug-related crimes.


```{r}

crimes_ex <- data.frame(
    Month       = "Jan",
    T           = 128,
    SinT        = sin(2 * pi * 128 / 12),
    CosT        = cos(2 * pi * 128 / 12),
    Borough     = "Bronx",
    Murder      = 20,
    Burglary    = 50,
    DrugRelated = seq(1000, 10000, 1000)
)
crimes_ex

{
pois_pred <- generate_predictions_with_ci(
    model = model.pois,
    newdata=crimes_ex,
    "Shootings", 
    response = "response",
    level = LEVEL
)

colnames(pois_pred)[colnames(pois_pred) == "Shootings"] <- "ShootingsPoisPred"
pois_pred$PoisPredSE <- pois_pred$Upper - pois_pred$ShootingsPoisPred

pois_pred$Lower <- NULL; pois_pred$Upper <- NULL
}

{
quasipois_pred <- generate_predictions_with_ci(
    model = model.quasipois,
    newdata=crimes_ex,
    "Shootings", 
    response = "response",
    level = LEVEL
)
colnames(quasipois_pred)[colnames(quasipois_pred) == "Shootings"] <- "ShootingsQuasipoisPred"
quasipois_pred$QuasipoisPredSE <- quasipois_pred$Upper - quasipois_pred$ShootingsQuasipoisPred
quasipois_pred$Lower <- NULL; quasipois_pred$Upper <- NULL
}

knit_table(
cbind(
    pois_pred     [, c("DrugRelated", "ShootingsPoisPred", "PoisPredSE")], 
    quasipois_pred[, c("ShootingsQuasipoisPred", "QuasipoisPredSE")]
))


rm(pois_pred, quasipois_pred, crimes_ex)
```

Despite the predictions being identical, the overdispersion makes the interval tend to be wider.

We can observe the increased uncertainty by visualizing the predictions of the Quasi-Poisson model on the training and test sets.

```{r}

plot_prediction(model.quasipois, "Quasi-Poisson")
plot_prediction(model.quasipois, "Quasi-Poisson", test=TRUE)
```

### 3.2. Negative Binomial

Another family of models explicitly designed for counting data is the Negative Binomial family. The assumptions of this model better align with the nature of the data because it assumes a variance larger than the mean and incorporates a dispersion parameter.


```{r}

model.nb <- glm.nb(
    Shootings ~ Borough + SinT + CosT +
    DrugRelated + Murder + Burglary,
    data = crimes
)

summary(model.nb)
```

The Negative Binomial model is significant for all predictors.
Let's see how it compares to the Poisson model in terms of $AIC$ and $BIC$.


```{r}

knit_table(stats_to_table(get_models_prediction_stats(
    models = list(
        Pois    = model.pois,
        NegBin  = model.nb
    ),
    df_ = crimes_test,
    y = "Shootings",
    glmnet_predictors = SHRINKAGE_PREDICTORS
))[,c(3, 4)])

```

The Negative Binomial model is indeed  better for both metrics, likely due to better assumption alignment with the nature of the data.

Finally, let's visualize its predictions on the training and test sets.


```{r}
plot_prediction(model.nb, "Negative Binomial")
plot_prediction(model.nb, "Negative Binomial", test=TRUE)
```

### 3.3. GAM

Now we employ Generalized Additive Models (GAMs), which allow us to introduce nonlinearity in predictors. In this regard, we have chosen a model that includes the three types of crimes as predictors to better investigate if there is any nonlinearity that could be an important factor in predicting the number of shootings.

#### 3.3.1. Poisson GAM

First, let's construct a Poisson GAM using splines for the arrest predictors.

```{r}
model.gam_pois <- gam(
    Shootings ~ Borough + CosT + SinT + 
        s(DrugRelated) + s(Murder) + s(Burglary),
    data = crimes,
    family = poisson
)

summary(model.gam_pois)
```

All terms are significant, including the splines. Let's visualize the effect that each predictor has on the smoothed term.

```{r}
par(mfrow=c(1, 3))
plot(model.gam_pois, shade = TRUE)
par(mfrow=c(1, 1))
```

Let's visualize the predictions of these models.

```{r}
plot_prediction(model.gam_pois, "GAM Poisson")
plot_prediction(model.gam_pois, "GAM Poisson", test=TRUE)
```

The models show particularly variable observations in some cases, especially in the boroughs of Bronx and Brooklyn.

### 3.3.2. Poisson NB

Let's repeat the same operation, this time using a Negative Binomial GAM.

```{r}

model.gam_nb <- gam(
    Shootings ~ Borough + CosT + SinT + 
        s(DrugRelated) + s(Murder) + s(Burglary),
    data = crimes,
    family = nb
)


summary(model.gam_nb)
```

Contrary to the previous model, the GAM associated with `Murder` is now less significant.

Let's visualize the effects of the splines.

```{r}
par(mfrow=c(1, 3))
plot(model.gam_nb, shade = TRUE)
par(mfrow=c(1, 1))
```

Finally, let's visualize the predictions on the training and test sets.

```{r}
plot_prediction(model.gam_nb, "GAM Negative Binomial")
plot_prediction(model.gam_nb, "GAM Negative Binomial", test=TRUE)
```

### 3.4. Counting models comparison

Now that we have considered various counting models, let's analyze their performance on the test set.

```{r}

models_stats <- get_models_prediction_stats(
    models = list(
        "Pois"      = model.pois,
        "QuasiPois" = model.quasipois,
        "NegBin"    = model.nb,
        "GAMPois"   = model.gam_pois,
        "GAMNegBin" = model.gam_nb
    ),
    df_ = crimes_test,
    y = "Shootings",
    glmnet_predictors = SHRINKAGE_PREDICTORS
)
out_table <- stats_to_table(models_stats)
out_table <- out_table[order(out_table$MSE), -c(1, 2)]
knit_table(out_table)

```

Examining the $AIC$ and $BIC$, it is evident that Generalized Additive Models (GAMs) generally outperform their linear counterparts, likely due to their ability to capture nonlinearity in the data. Additionally, models employing the Negative Binomial distribution show superior performance compared to Poisson models, presumably because they can accommodate greater variance relative to the mean.

Nevertheless, the Poisson models incorporating three types of crimes as predictors achieve the lowest MSE and exhibit lower uncertainty.

This phenomenon may be partly attributed to the other models closely overfitting the training data, thereby restricting their ability to generalize to new observations. This inverse relationship between $AIC$ and MSE appears to substantiate this observation.

## 4. Conclusion

In this notebook, we have analyzed various count models to predict the number of shootings that occurred in New York City. We began with a Poisson model and then explored Quasi-Poisson, Negative Binomial, and Generalized Additive Models.

Among these models, the Quasi-Poisson model emerges as the best performer on unseen data, aligning well with the assumptions about shooting incidents.

The phenomenon of shootings exhibits a strong seasonal component, with counts varying significantly throughout the year. Overall, the pehomenon is closely tied to the total number of arrests in the city's recent past, where shootings tend to increase in response to both an increase and a decrease in arrests.

Specifically, crimes related to drug-related arrests notably influence shootings, which are in turn closely associated with acts of vandalism and assaults like bribery and theft.

Generally, this phenomenon affects the entire city uniformly, with some boroughs characterized by higher crime rates on average. This is not the case for Staten Island borough, which generally has very low rates of shootings and arrests.

---