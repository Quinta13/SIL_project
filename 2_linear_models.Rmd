---
title: "NYC Shootings and Arrests - Linear Models"
author: "Sebastiano Quintavale - 878500"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
    html_document:
        toc: true
        toc_float: true
        theme: cerulean
        highlight: tango
---

```{r echo=FALSE, include=FALSE}

# 1. RMardown styling
knitr::opts_chunk$set(echo=FALSE)
knitr::opts_chunk$set(fig.width = 12, fig.height = 8)

# 2. Project environment setup
source("src/init.R")

```

```{r}

# Load data
crimes <- read.csv(PATHS$NycMonthCrimes)

# Add discrete version for Month and Year
prepare_out <- prepare_crimes(crimes_df=crimes)

crimes      <- prepare_out$df
CRIME_NAMES <- prepare_out$crime_names

rm(prepare_out)

# Split Train and Test
split <- train_test_split_by_year(df_ = crimes, year_test = YEAR_TEST)
crimes <- split$train
crimes_test <- split$test
rm(split)

split_out <- split_statenisland(crimes=crimes, crimes_test=crimes_test)

crimes         <- split_out$crimes
crimes_test    <- split_out$crimes_test
si_crimes      <- split_out$si_crimes
si_crimes_test <- split_out$si_crimes_test

rm(split_out)



crimes <- prepare_outliers(crimes)

```


## Staten Island

```{r}

plot(si_crimes)

```

### Overview

Average per year

```{r}
knit_table(round(t(df_group_stats(si_crimes, "Year", "Shootings")), 3))
```

Month 
```{r}
knit_table(round(t(df_group_stats(si_crimes, "MonthName", "Shootings")), 3))
```


### Time series Decomposition

Ts with average
```{r}
plot_ts(
    df_ts = ts_crimes_reshape(si_crimes),
    group = "CrimeType",
    y     = "Shootings",
    ylab  = "Shootings",
    title = "Shootings in StatenIsland",
    title.size = 18,
    lwd   = 0.7,
    col   = "#030a35"
) +
    geom_hline(yintercept = mean(si_crimes$Shootings), linetype = "dashed", color = "#e24000df", linewidth = 1.5)
```

Decomposition

```{r}
plot_ts_stl_decomposition(
    df_ = si_crimes,
    y = "Shootings",
    title = "Shootings in StatenIsland"
)
```

```{r}
# Linear models
si_models <- list()
```

### Null model

```{r}

# Null model predicting the mean level
si_models$null <- lm(Shootings ~ 1, data = si_crimes)

lm_diagnostic(
    si_models$null, 
    residuals = FALSE, 
    effects   = FALSE,
    vif       = FALSE
)

si_crimes[c(9, 42), c("Year", "Month", "Shootings")]
```

High number

### Month model

```{r}
# Using month levels with constraints they sum up to 0
contrasts(si_crimes     $MonthName) <- contr.sum(12)
contrasts(si_crimes_test$MonthName) <- contr.sum(12)

si_models$month <- lm(
    Shootings ~ MonthName, 
    data = si_crimes
)

lm_diagnostic(
    si_models$month, 
    influencial_points = FALSE,
    effects = FALSE,
    vif = FALSE
)
```

We plot coefficients for the month with respect to the average number of shootings r`mean(si_crimes$Shootings)`.

```{r}
plot_model_coefficients(
    coefs  = si_models$month$coefficients[2:12],
    xlab   = "Month",
    title  = "StatenIsland Month Coefficients",
    labels = month.abb
)

```

Only significant are the rwo month more distant to the mean, Feb in negative and july in postiive, the seasonal effect has impact on just one number of shootings as shown in the stl decomposition.


### Crimes models
```{r}

si_models$crimes <- lm(
    Shootings ~ DrugRelated,
    data = si_crimes
)

lm_diagnostic(
    si_models$crimes,
    influencial_points = TRUE,
    effects = TRUE,
    vif   = FALSE
)
```

All significative. Similar adjusted R^2
Vif no multicollineratiy

### Step wise regression

```{r}
# Select the best model using step subset selection leaps library
subset_regression_info(
    subset_reg = regsubsets(
        Shootings ~ . - Year - TotArrests - Month,
        data = si_crimes,
        nvmax = 21
    )
)
```

We seelect the number of variables selected by BIC.

Use two crimes plus the two months that have higher lowest value.

```{r}

# Select the regsubsets model with 4 predictors
si_models$stepwise <- lm(
    Shootings ~ DrugRelated + Offense + Murder +
        as.numeric(MonthName == "Feb") +
        as.numeric(MonthName == "Jul"),
    data = si_crimes
)

lm_diagnostic(
    si_models$stepwise,
    effects = FALSE,
    influencial_points = FALSE
)

```

### Model comparison

### Prediciton plots

Train

```{r}
invisible(plot_multiple_model_predictions_over_time(
    df_ = si_crimes,
    models = si_models,
    y = "Shootings",
    title = "Shootings in Queens - Training set predictions",
    ylab = "Shootings incidents",
    level = LEVEL,
    lwd = 1,
    ticks = 3,
    lwd_observations = 0.5,
    grid_rows=2
))
```

Don't cover picks, probably errors difficult to model

```{r}

invisible(plot_multiple_model_predictions_over_time(
    df_ = si_crimes_test,
    models = si_models,
    y = "Shootings",
    title = "Shootings in Queens - Test set predictions",
    ylab = "Shootings incidents",
    level = LEVEL,
    lwd = 1,
    ticks = 3,
    lwd_observations = 0.5,
    grid_rows=2
))
```

### Prediction metrics

```{r}
knit_table(
    stats_to_table(
        get_models_prediction_stats(
            models = si_models,
            df_ = si_crimes_test,
            y = "Shootings"
        )
    )
)
```

Discuss also in terms of varaiblity!

## NYC Boroughs


```{r}
plot_prediction <- function(model, name, train=TRUE) {

    if(train) {
        df_ <- crimes
    } else {
        df_ <- crimes_test
    }

    invisible(
    plot_model_predictions_per_level_over_time(
        model = model,
        df_ =df_,
        y = "Shootings",
        levels = "Borough",
        title = paste("Shootings per Borough Prediction -", name, "-", ifelse(train, "Training", "Test"), "set"),
        ylab = "Shootings incidents",
        level = LEVEL,
        ticks = ifelse(train, 12, 5),
        lwd = 0.35,
        lwd_observations = 0.35,
        colors = unlist(PALETTE$boroughs),
        grid_rows = 2,
        glmnet_predictors = SHRINKAGE_PREDICTORS
    )
    )

}
```
### Time series overview

Inspect times series

```{r}
plot_multiple_ts(
    df_ts = ts_borough_reshape(
        df_ = crimes[, c("Borough", "Year", "MonthName", "Shootings")],
        crime_type = "Shootings"
    ),
    ylab   = "Incidents",
    group  = "Borough",
    title  = "Shootings in NYC Boroughs - 2006 to 2021",
    lwd    = 0.8,
    colors = unlist(PALETTE$boroughs),
    ticks  = 3,
    title_size = 16
)
```

Look at their decomposition

```{r}
for (borough in unique(crimes$Borough)) {
    df_ <- crimes[crimes$Borough == borough, ]

    plot_ts_stl_decomposition(
        df_ = df_, y = "Shootings", title = paste(borough, "- STL Decomposition")
    )
}

```

All have seasonal component and a trend during year, with errorc component very important, maybe we can explain it with crimes.


Introduction
```{r}
models <- list()
```

### Month seasonality

Scatterplot monthly.
```{r}
levels_scatterplot(
    df_ = crimes,
    x = "Month",
    y = "Shootings",
    levels = "Borough",
    title = "Shootings during year across Boroughs",
    jitter_ = TRUE,
    colors = unlist(PALETTE$boroughs),
    size = 2
)
```

Clear seasonal effect with a rise in the summer period a smaller rise in january-december.

```{r}

contrasts(crimes     $MonthName) <- contr.sum(12)
contrasts(crimes_test$MonthName) <- contr.sum(12)

models$month_steps <- lm(
    Shootings ~ MonthName + Borough,
    data = crimes
)

lm_diagnostic(
    models$month_steps,
    vif = FALSE,
    influencial_points = FALSE
)

plot_prediction(models$month_steps, "Month Steps")
plot_prediction(models$month_steps, "Month Steps", train=FALSE)

```

### Model seasonality with goniometri function

Periodic component we can think of modelling with sign and cosine

```{r}

models$periodic <- lm(
    Shootings ~ sin(2 * pi * T / 12) + cos(2 * pi * T / 12) + Borough,
    data = crimes
)

plot_prediction(models$periodic, "Periodic")
plot_prediction(models$periodic, "Periodic", train=FALSE)

stats_to_table(get_models_prediction_stats(
    models = list(
        MonthSteps = models$month_steps,
        Periodic   = models$periodic
    ),
    df_ = crimes_test,
    y = "Shootings"
))[, 1:4]
```

### Add trend information

```{r}
# Add time indicator

models$trended <- lm(
    Shootings ~ T + I(T^2) + I(T^3) + sin(2 * pi * T / 12) + cos(2 * pi * T / 12) + Borough,
    data = crimes
)

lm_diagnostic(
    models$trended, 
    effects = FALSE,
    vif = FALSE,
    influencial_points = FALSE
)

plot_prediction(models$trended, "Trended")
plot_prediction(models$trended, "Trended", train=FALSE)

stats_to_table(get_models_prediction_stats(
    models = list(
        NoTrend = models$periodic,
        Trend   = models$trended
    ),
    df_ = crimes_test,
    y = "Shootings"
))[, 1:4]

```


### Total Arrests

```{r}

totarrests <- lm(
    Shootings ~ TotArrests,
    data = crimes
)

lm_diagnostic(
    totarrests,
    effects=FALSE, vif=FALSE, influencial_points=FALSE
)



```

```{r}
totarrests2 <- lm(
    Shootings ~ TotArrests +I(TotArrests^2),
    data = crimes
)


lm_diagnostic(
    totarrests2,
    effects=FALSE, vif=FALSE
)

# Find points with Cook's distance > 0.2
summary(
crimes[
    which(cooks.distance(totarrests2) > 0.005), 
    c("Year", "MonthName", "Borough", "TotArrests", "Shootings")
])


plot_multiple_model_prediction(
    df_=crimes,
    models = list(
        Linear = totarrests,
        Square = totarrests2
    ),
    x="TotArrests", y="Shootings", 
    title="Arrests Impact on Shootings - Training set",
    xlab="Total Arrests", ylab ="Shootings Incidents",
    jitter_=TRUE,
    level = LEVEL,
    colors = c("#c23512e7", "#0050ace7")
)

rm(list=c("totarrests", "totarrests2"))
```

Most of leverage point comes from picks in summer or falls in winter that are difficult to model.

```{r}

models$tot_arrests <- lm(
    Shootings ~ TotArrests + I(TotArrests^2) + Borough,
    data = crimes
)

lm_diagnostic(
    models$tot_arrests,
    effects=FALSE, vif=FALSE, influencial_points=FALSE
)

plot_model_prediction_per_level(
    model  = models$tot_arrests,
    df_    = crimes,
    x      = "TotArrests",
    y      = "Shootings",
    levels = "Borough",
    title  = "Arrests impact on Shooting across Boroughs",
    xlab   = "Total Arrests",
    ylab   = "Shootings incidents",
    level  = LEVEL,
    colors = unlist(PALETTE$boroughs)
)

plot_prediction(models$tot_arrests, "Total Arrests")
plot_prediction(models$tot_arrests, "Total Arrests", train=FALSE)
```

```{r}

models$tot_arrests_I <- lm(
    Shootings ~ TotArrests * Borough + I(TotArrests^2) * Borough,
    data = crimes
)

lm_diagnostic(
    models$tot_arrests_I,
    effects=FALSE, vif=FALSE, influencial_points=FALSE
)

stats_to_table(get_models_prediction_stats(
    models = list(
        TotArrests            = models$tot_arrests,
        TotArrestsInteraction = models$tot_arrests_I
    ),
    df_ = crimes_test,
    y = "Shootings"
))[, 1:4]

```

### Total Arrests and Periodic



```{r}
models$periodic_totarrests <- lm(
    Shootings ~ sin(2 * pi * T / 12) + cos(2 * pi * T / 12) + 
    Borough + TotArrests + I(TotArrests^2),
    data = crimes
)

lm_diagnostic(
    models$periodic_totarrests,
    effects = FALSE,
    influencial_points=FALSE
)

plot_prediction(models$periodic_totarrests, "Periodic and Total Arrests")
plot_prediction(models$periodic_totarrests, "Periodic and Total Arrests", train=FALSE)
```

Can in a way follow the trend and not degenrate as trying to fit a polynomial with the epoch

Better describe

### Crimes model

Let's see role of individual crime
```{r}
one_crime_model <- list()

for(crime in CRIME_NAMES) {
    one_crime_model[[crime]] <- lm(
        as.formula(paste0("Shootings ~", crime)),
        data = crimes
    )
}

stats_to_table(get_models_prediction_stats(
    models = one_crime_model,
    df_ = crimes,
    y = "Shootings"
))[, c(1, 3, 4)]

```

Even if theorretically better we have fourten the predictors most are not significative we keep a simpler one to gain in interprettoin

### Stepwise serach

```{r}

crime_tmp <- crimes[, !(names(crimes) %in% c("TotArrests", "Year"))]

models$stepwise <- step(
    lm(Shootings ~ 1, data=crime_tmp),
    scope = list(lower = lm(Shootings ~ 1, data=crime_tmp), upper = lm(Shootings ~ ., data=crime_tmp)),
    direction = "both",
    k = log(nrow(crime_tmp))
)

lm_diagnostic(
    models$stepwise,
    influencial_points = FALSE
)



```

Clear problem of multicollinearity and quadratic residuals for Offense crimes and also for MonthName

### Crime specific

```{r}
models$stepwise <- NULL

models$crimes <- lm(
    Shootings ~ sin(2 * pi * T / 12) + cos(2 * pi * T / 12) + Borough + Offense + Burglary + Murder,
    data = crimes
)

lm_diagnostic(models$crimes, effects=FALSE)

crimes[
    which(cooks.distance(models$crimes) > 0.02), 
    c("Year", "MonthName", "Borough", "Offense", "Burglary", "Murder", "Shootings")
]

stats_to_table(get_models_prediction_stats(
    models = list(
        TotArrests      = models$tot_arrests,
        CrimeSpecific = models$crimes
    ),
    df_ = crimes,
    y = "Shootings"
))[, c(2, 3, 4)]

```



```{r}

plot_prediction(models$crimes, "Crime specific")
plot_prediction(models$crimes, "Crime specific", train=FALSE)

```


### Shrinkage selection

```{r}

# TODO Chiedere al colloquio se escludere Larceny
SHRINKAGE_PREDICTORS <- c(
    CRIME_NAMES, "Borough", "T", "MonthName"
)

gs <- round(shrinkage_grid_search(
    df_ = crimes[, c(SHRINKAGE_PREDICTORS, "Shootings")], 
    y="Shootings", 
    alphas=c(0, 1-0.0002, 1)
), 3)

gs <- as.matrix(gs); gs[gs == 0] <- "."
knit_table(gs)
rm(gs)

```

```{r}

models$shrinkage <- shrinkage_selection(
    df_ = crimes[, c(SHRINKAGE_PREDICTORS, "Shootings")],
    y = "Shootings",
    type = "1se",
    alpha = 1
)

coef(models$shrinkage)

```

```{r}

plot_prediction(models$shrinkage, name="Shrinkage")
plot_prediction(models$shrinkage, name="Shrinkage", train=FALSE)

```


### Model comparison

```{r}
models$mean         <- lm(Shootings ~ 1,       data=crimes)
models$borough_mean <- lm(Shootings ~ Borough, data=crimes)
```

```{r}

models_stats <- get_models_prediction_stats(
    models = models,
    df_ = crimes_test,
    y = "Shootings",
    glmnet_predictors = SHRINKAGE_PREDICTORS
)
out_table <- stats_to_table(models_stats)
knit_table(out_table)

```




```{r}

```
